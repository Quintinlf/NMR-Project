{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c170ea09",
   "metadata": {},
   "source": [
    "### data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec8f580",
   "metadata": {},
   "source": [
    "# ğŸ“Š Refactoring NMR Analysis for Reusability\n",
    "\n",
    "This notebook demonstrates how to **modularize and refactor** the original NMR analysis workflow into clean, reusable components. The aim is to create a flexible and maintainable codebase for future applications, including:\n",
    "\n",
    "- ğŸ“ **Data loading**\n",
    "- ğŸ”„ **Fourier transform**\n",
    "- ğŸ” **Peak detection**\n",
    "- ğŸ“ˆ **Integration**\n",
    "- ğŸ§ª **Functional group identification**\n",
    "- âš›ï¸ **Quantum-level simulation**\n",
    "\n",
    "All the functions and classes used here are refactored from the original `main_project.ipynb` file.\n",
    "\n",
    "By restructuring the code into **functions and classes**, we enable:\n",
    "- ğŸš€ Faster prototyping\n",
    "- ğŸ”§ Easier debugging and testing\n",
    "- â™»ï¸ Reusability across projects\n",
    "- ğŸ“¦ Potential packaging into libraries or APIs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a06b55",
   "metadata": {},
   "source": [
    "## 1. Encapsulate Data Loading and Preprocessing\n",
    "\n",
    "We'll create a function `load_nmr_data(filepath)` to load and preprocess the NMR data. This function can be extended to handle different file formats or preprocessing steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99bcaab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def load_nmr_data(filepath, delimiter='\\t', skip_header=1, columns=('Time', 'Real', 'Imaginary')):\n",
    "    \"\"\"\n",
    "    Load NMR data from a file and return as a DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "        filepath (str): Path to the data file.\n",
    "        delimiter (str): Delimiter used in the file.\n",
    "        skip_header (int): Number of header lines to skip.\n",
    "        columns (tuple): Column names for the DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with columns ['Time', 'Real', 'Imaginary'].\n",
    "    \"\"\"\n",
    "    data = np.genfromtxt(filepath, delimiter=delimiter, skip_header=skip_header)\n",
    "    df = pd.DataFrame(data, columns=columns)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e13b5f8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Time      Real  Imaginary\n",
      "0  0.000000  0.000003   0.000009\n",
      "1  0.000133 -0.001235  -0.003140\n",
      "2  0.000267  0.050601   0.188029\n",
      "3  0.000400  0.019175   0.365893\n",
      "4  0.000533 -0.136525  -0.611649\n"
     ]
    }
   ],
   "source": [
    "file_path = \"13_03_11_indst_1H fid.asc\"\n",
    "df = load_nmr_data(file_path)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f00218c",
   "metadata": {},
   "source": [
    "## 2. Refactor Nyquist Frequency Calculation into a Function\n",
    "\n",
    "We'll define a function `calculate_nyquist_frequency(time_array)` that takes an array of time points and returns the Nyquist frequency. This makes the calculation reusable and clear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d9ede29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_nyquist_frequency(time_array):\n",
    "    \"\"\"\n",
    "    Calculate the Nyquist frequency from an array of time points.\n",
    "\n",
    "    Parameters:\n",
    "        time_array (np.ndarray): Array of time points (in seconds).\n",
    "\n",
    "    Returns:\n",
    "        float: Nyquist frequency in Hz.\n",
    "    \"\"\"\n",
    "    if len(time_array) < 2:\n",
    "        raise ValueError(\"Need at least two time points to calculate dwell time.\")\n",
    "    dwell_time = time_array[1] - time_array[0]\n",
    "    nyquist_freq = 1 / (2 * dwell_time)\n",
    "    return nyquist_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e640a5c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nyquist frequency: 3751.50 Hz\n"
     ]
    }
   ],
   "source": [
    "nyquist_freq = calculate_nyquist_frequency(df[\"Time\"].values)\n",
    "print(f\"Nyquist frequency: {nyquist_freq:.2f} Hz\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b013f9",
   "metadata": {},
   "source": [
    "## 3. Create a Class for NMR Spectrum Analysis\n",
    "\n",
    "We'll define a class `NMRSpectrum` that encapsulates the workflow: loading data, performing FFT, detecting peaks, integrating, and plotting. This class will store relevant attributes and provide methods for each analysis step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84d476af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.fft import fft, fftfreq, fftshift\n",
    "from scipy.signal import find_peaks\n",
    "from scipy.integrate import simpson\n",
    "\n",
    "class NMRSpectrum:\n",
    "    def __init__(self, time, real, imaginary=None, name=None, spectrometer_freq=None):\n",
    "        self.time = np.array(time)\n",
    "        self.real = np.array(real)\n",
    "        self.imaginary = np.array(imaginary) if imaginary is not None else None\n",
    "        self.name = name\n",
    "        self.spectrometer_freq = spectrometer_freq\n",
    "        self.fft_result = None\n",
    "        self.frequencies = None\n",
    "        self.fft_magnitude = None\n",
    "        self.peaks = None\n",
    "        self.peak_properties = None\n",
    "        self.integrated_areas = None\n",
    "\n",
    "    @classmethod\n",
    "    def from_dataframe(cls, df, name=None, spectrometer_freq=None):\n",
    "        return cls(df['Time'], df['Real'], df.get('Imaginary', None), name, spectrometer_freq)\n",
    "\n",
    "    def compute_fft(self):\n",
    "        dwell_time = self.time[1] - self.time[0]\n",
    "        self.fft_result = fft(self.real)\n",
    "        self.frequencies = fftfreq(len(self.real), d=dwell_time)\n",
    "        self.fft_magnitude = np.abs(self.fft_result)\n",
    "        return self.frequencies, self.fft_magnitude\n",
    "\n",
    "    def detect_peaks(self, height_ratio=0.1, min_distance=100, min_prominence=0.05):\n",
    "        if self.fft_magnitude is None:\n",
    "            raise ValueError(\"Run compute_fft() first.\")\n",
    "        height_threshold = height_ratio * np.max(self.fft_magnitude)\n",
    "        min_prom = min_prominence * np.max(self.fft_magnitude)\n",
    "        peaks, properties = find_peaks(\n",
    "            self.fft_magnitude,\n",
    "            height=height_threshold,\n",
    "            distance=min_distance,\n",
    "            prominence=min_prom\n",
    "        )\n",
    "        self.peaks = peaks\n",
    "        self.peak_properties = properties\n",
    "        return peaks, properties\n",
    "\n",
    "    def integrate_peaks(self):\n",
    "        if self.peaks is None or self.peak_properties is None:\n",
    "            raise ValueError(\"Run detect_peaks() first.\")\n",
    "        integrated_areas = []\n",
    "        for i, peak_idx in enumerate(self.peaks):\n",
    "            left = self.peak_properties['left_bases'][i]\n",
    "            right = self.peak_properties['right_bases'][i]\n",
    "            freq_region = self.frequencies[left:right+1]\n",
    "            mag_region = self.fft_magnitude[left:right+1]\n",
    "            area = simpson(mag_region, freq_region)\n",
    "            integrated_areas.append(area)\n",
    "        self.integrated_areas = integrated_areas\n",
    "        return integrated_areas\n",
    "\n",
    "    def normalize_integrals(self):\n",
    "        if self.integrated_areas is None:\n",
    "            raise ValueError(\"Run integrate_peaks() first.\")\n",
    "        min_area = min(self.integrated_areas)\n",
    "        return [area / min_area for area in self.integrated_areas]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1cbda0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "63e045cb",
   "metadata": {},
   "source": [
    "## 4. Modularize Fourier Transform and Frequency Axis Calculation\n",
    "\n",
    "The Fourier transform logic is encapsulated in the `compute_fft` method of the `NMRSpectrum` class. You can also define a standalone function if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61592c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_fft(real_signal, dwell_time):\n",
    "    \"\"\"\n",
    "    Compute the FFT, frequency axis, and magnitude for a real signal.\n",
    "\n",
    "    Parameters:\n",
    "        real_signal (np.ndarray): The real part of the signal.\n",
    "        dwell_time (float): Time between points (seconds).\n",
    "\n",
    "    Returns:\n",
    "        tuple: (frequencies, fft_result, fft_magnitude)\n",
    "    \"\"\"\n",
    "    fft_result = fft(real_signal)\n",
    "    frequencies = fftfreq(len(real_signal), d=dwell_time)\n",
    "    fft_magnitude = np.abs(fft_result)\n",
    "    return frequencies, fft_result, fft_magnitude"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0997eae9",
   "metadata": {},
   "source": [
    "## 5. Encapsulate Peak Detection and Integration\n",
    "\n",
    "Peak detection and integration are provided as methods in the `NMRSpectrum` class, but you can also use standalone functions for flexibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dea17fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_peaks(magnitude, height_ratio=0.1, min_distance=100, min_prominence=0.05):\n",
    "    \"\"\"\n",
    "    Detect peaks in a magnitude array.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (peaks, properties)\n",
    "    \"\"\"\n",
    "    height_threshold = height_ratio * np.max(magnitude)\n",
    "    min_prom = min_prominence * np.max(magnitude)\n",
    "    peaks, properties = find_peaks(\n",
    "        magnitude,\n",
    "        height=height_threshold,\n",
    "        distance=min_distance,\n",
    "        prominence=min_prom\n",
    "    )\n",
    "    return peaks, properties\n",
    "\n",
    "def integrate_peaks(frequencies, magnitudes, peaks, properties):\n",
    "    \"\"\"\n",
    "    Integrate each detected peak using Simpson's rule.\n",
    "\n",
    "    Returns:\n",
    "        list: Integrated areas for each peak.\n",
    "    \"\"\"\n",
    "    areas = []\n",
    "    for i, peak_idx in enumerate(peaks):\n",
    "        left = properties['left_bases'][i]\n",
    "        right = properties['right_bases'][i]\n",
    "        freq_region = frequencies[left:right+1]\n",
    "        mag_region = magnitudes[left:right+1]\n",
    "        area = simpson(mag_region, freq_region)\n",
    "        areas.append(area)\n",
    "    return areas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e558b41c",
   "metadata": {},
   "source": [
    "## 6. Create Functional Group Identification as a Function\n",
    "\n",
    "Refactor the functional group identification logic into a reusable function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59620b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_functional_groups(frequencies, magnitudes, ppm_shifts):\n",
    "    \"\"\"\n",
    "    Identify functional groups based on peak positions in the spectrum.\n",
    "\n",
    "    Parameters:\n",
    "        frequencies (np.ndarray): Frequencies in ppm.\n",
    "        magnitudes (np.ndarray): Magnitudes of the FFT result.\n",
    "        ppm_shifts (dict): Mapping of functional groups to their ppm ranges.\n",
    "\n",
    "    Returns:\n",
    "        list: List of (peak_ppm, group) tuples.\n",
    "    \"\"\"\n",
    "    peaks, _ = find_peaks(magnitudes, height=0.1 * max(magnitudes))\n",
    "    peak_positions = frequencies[peaks]\n",
    "    identified_groups = []\n",
    "    for peak in peak_positions:\n",
    "        for group, ppm_range in ppm_shifts.items():\n",
    "            ppm_min, ppm_max = map(float, ppm_range.replace(\"ppm\", \"\").split(\"-\"))\n",
    "            if ppm_min <= peak <= ppm_max:\n",
    "                identified_groups.append((peak, group))\n",
    "                break\n",
    "    return identified_groups"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b621e57",
   "metadata": {},
   "source": [
    "## 7. Encapsulate Multiplet and J-Coupling Analysis\n",
    "\n",
    "Write functions for multiplet detection and J-coupling estimation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc07033",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_multiplet(ppm_axis, intensity, center_ppm, spectrometer_freq, window=0.05):\n",
    "    \"\"\"\n",
    "    Analyze a multiplet region and estimate J-couplings.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (sub_ppms, j_couplings)\n",
    "    \"\"\"\n",
    "    mask = (ppm_axis > center_ppm - window) & (ppm_axis < center_ppm + window)\n",
    "    sub_peaks, _ = find_peaks(intensity[mask], height=0.1 * max(intensity[mask]))\n",
    "    sub_ppms = ppm_axis[mask][sub_peaks]\n",
    "    sub_ppms = np.sort(sub_ppms)\n",
    "    j_couplings = []\n",
    "    for i in range(1, len(sub_ppms)):\n",
    "        ppm_diff = abs(sub_ppms[i] - sub_ppms[i - 1])\n",
    "        j_hz = ppm_diff * spectrometer_freq\n",
    "        j_couplings.append(j_hz)\n",
    "    return sub_ppms, j_couplings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c9a10c",
   "metadata": {},
   "source": [
    "## 8. Modularize Quantum Simulation Components\n",
    "\n",
    "Encapsulate quantum simulation logic into a class, e.g., `SpinHamiltonian`, with methods for building the Hamiltonian, solving eigenstates, and animating time evolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17d6ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class SpinHamiltonian:\n",
    "    def __init__(self, n_spins, j_couplings=None, bx=5):\n",
    "        self.n_spins = n_spins\n",
    "        self.j_couplings = j_couplings if j_couplings is not None else [7] * (n_spins - 1)\n",
    "        self.bx = bx\n",
    "        self.I = np.eye(2)\n",
    "        self.sz = np.array([[1, 0], [0, -1]]) / 2\n",
    "        self.sx = np.array([[0, 1], [1, 0]]) / 2\n",
    "        self.H = None\n",
    "\n",
    "    def build_hamiltonian(self):\n",
    "        from numpy import kron\n",
    "        Iz_ops = []\n",
    "        Ix_ops = []\n",
    "        for i in range(self.n_spins):\n",
    "            op_z = 1\n",
    "            op_x = 1\n",
    "            for j in range(self.n_spins):\n",
    "                op_z = kron(op_z, self.sz if i == j else self.I)\n",
    "                op_x = kron(op_x, self.sx if i == j else self.I)\n",
    "            Iz_ops.append(op_z)\n",
    "            Ix_ops.append(op_x)\n",
    "        H = 0\n",
    "        for i in range(self.n_spins):\n",
    "            for j in range(i + 1, self.n_spins):\n",
    "                J = self.j_couplings[0] if self.j_couplings else 7\n",
    "                H += 2 * np.pi * J * Iz_ops[i] @ Iz_ops[j]\n",
    "        for i in range(self.n_spins):\n",
    "            H += 2 * np.pi * self.bx * Ix_ops[i]\n",
    "        self.H = H\n",
    "        return H\n",
    "\n",
    "    def solve(self):\n",
    "        if self.H is None:\n",
    "            self.build_hamiltonian()\n",
    "        eigvals, eigvecs = np.linalg.eigh(self.H)\n",
    "        return eigvals, eigvecs\n",
    "\n",
    "    # You can add methods for time evolution and animation as needed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac896a80",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "- **Reusable functions**: For Nyquist frequency, data loading, FFT, peak detection, integration, functional group identification, and multiplet analysis.\n",
    "- **Classes**: `NMRSpectrum` for spectrum analysis and `SpinHamiltonian` for quantum simulation.\n",
    "- **Next steps**: Move these functions and classes into a `.py` file (e.g., `nmr_utils.py`) for import into future notebooks or scripts."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
